import json
import datetime
from pathlib import Path


def fourier_inverse_square_benchmark(g_samples: list[float], dt: float) -> float:
    """Toy Fourier-space benchmark integral with an inverse-square weight.

    This is *not* a full implementation of a model-specific QEI bound, which
    requires additional state/field data. It exists to support numerical
    sanity-checks and figure generation that compare proxy bounds against a
    representative inverse-frequency weighting.

    Returns a nonnegative scalar.
    """

    if dt <= 0:
        raise ValueError("dt must be positive")
    if not g_samples:
        raise ValueError("g_samples must be non-empty")

    try:
        import numpy as np
    except Exception as e:  # pragma: no cover
        raise RuntimeError("numpy is required for Fourier benchmark") from e

    g = np.asarray(g_samples, dtype=float)
    n = int(g.shape[0])
    freqs = np.fft.fftfreq(n, d=float(dt))
    g_hat = np.fft.fft(g)

    eps = 1e-12
    weight = 1.0 / (freqs * freqs + eps)
    # Discrete sum as a rough stand-in for a continuum integral.
    val = (1.0 / (2.0 * np.pi)) * float(np.sum(np.abs(g_hat) ** 2 * weight))
    return max(0.0, val)


def _as_lean_string(s: str) -> str:
    return '"' + s.replace('\\', '\\\\').replace('"', '\\"') + '"'


def _as_lean_float(x) -> str:
    # Lean's Float literals accept standard decimal / scientific notation.
    if isinstance(x, (int, float)):
        return repr(float(x))
    return repr(float(x))


def generate_lean_candidates(results_dir: Path, out_file: Path, top_k: int = 5) -> None:
    """Generate a Lean documentation file for candidate vertex data.

    Reads vertex.json (the certified LP vertex) and top_near_misses.json (if
    available) from results_dir and produces a self-contained Lean comment block
    that records the candidate data for human inspection.  The formal
    certification itself lives in AQEI_Generated_Data_Rat.lean; this file serves
    as a human-readable companion for the pipeline audit trail.
    """
    results_dir = Path(results_dir)
    out_file = Path(out_file)
    out_file.parent.mkdir(parents=True, exist_ok=True)

    lines: list[str] = []
    lines.append("import Std")
    lines.append("")
    lines.append("/- Auto-generated by python/analyze_results.py.")
    lines.append("   Formal certification uses AQEI_Generated_Data_Rat.lean. -/")
    lines.append("")

    # Try to load the certified vertex from vertex.json.
    vertex_path = results_dir / "vertex.json"
    if vertex_path.exists():
        data = json.loads(vertex_path.read_text())
        a = data.get("a", [])
        active_indices = data.get("activeIndices", [])
        constraints = data.get("constraints", [])

        lines.append("/- Certified LP vertex (floating-point):")
        lines.append(f"   Coefficients a = {a}")
        lines.append(f"   Active AQEI constraint indices: {active_indices}")
        lines.append(f"   Number of active constraints: {len(constraints)} AQEI + box")
        lines.append("   See AQEI_Generated_Data_Rat.lean for the exact rational form")
        lines.append("   used in the Lean formal proof (FinalTheorems.lean).")
        lines.append("-/")
        lines.append("")

        # Emit one Lean Float constant per active constraint bound for cross-checking.
        lines.append("namespace GeneratedCandidates")
        lines.append("")
        lines.append("/-- Active-constraint B values (proxy bounds B_model) from vertex.json --/")
        for k, c in enumerate(constraints[:top_k]):
            b_val = c.get("B", 0.0)
            lines.append(f"def active_B_{k} : Float := {_as_lean_float(b_val)}")
        lines.append("")
        lines.append("end GeneratedCandidates")
    else:
        # No vertex data available yet; write a minimal placeholder.
        lines.append("/- No vertex.json found in results_dir at generation time.")
        lines.append("   Run the Mathematica search (mathematica/search.m) to produce it. -/")

    # Try to load near-miss candidates for the audit log.
    top_path = results_dir / "top_near_misses.json"
    if top_path.exists():
        near_miss_data = json.loads(top_path.read_text())[:top_k]
        lines.append("")
        lines.append(f"/- {len(near_miss_data)} near-miss candidate(s) from top_near_misses.json also")
        lines.append("   available for independent analysis. -/")

    lines.append("")
    out_file.write_text("\n".join(lines) + "\n")
    print(f"Wrote {out_file}")


def export_pipeline_validation(results_dir: Path) -> None:
    """Validate the LP vertex and export an audit artifact (pipeline_validation.json).

    Reads vertex.json and (if present) search_candidate.json, then performs
    three checks described in the paper's Computational Methodology section:

      1. Active-constraint saturation: every active AQEI constraint satisfies
         L·a + B ≈ 0 (tight binding).
      2. Inactive-constraint feasibility: every constraint not in the active
         set satisfies L·a + B ≥ 0 (feasibility for the full LP).
      3. LP optimality: re-solve the LP with SciPy using the stored objective
         and constraint data; confirm the re-solved objective value matches the
         certified vertex to within numerical tolerance.

    Results are written to pipeline_validation.json for independent
    re-checking by reviewers, as described in the paper.
    """
    results_dir = Path(results_dir)
    vertex_path = results_dir / "vertex.json"
    if not vertex_path.exists():
        print("pipeline_validation: vertex.json not found, skipping validation export")
        return

    data = json.loads(vertex_path.read_text())
    a = data.get("a", [])
    active_indices = data.get("activeIndices", [])
    active_constraints = data.get("constraints", [])

    # ── Check 1: active-constraint saturation ────────────────────────────────
    saturation_records = []
    all_tight = True
    for idx, c in zip(active_indices, active_constraints):
        L = c.get("L", [])
        B = float(c.get("B", 0.0))
        La = sum(float(li) * float(ai) for li, ai in zip(L, a))
        residual = abs(La + B)
        tight = residual < 1e-6
        if not tight:
            all_tight = False
        saturation_records.append({
            "constraint_index": idx,
            "La_plus_B": La + B,
            "abs_residual": residual,
            "tight": tight,
        })

    # ── Check 2: inactive-constraint feasibility (needs search_candidate.json) ─
    feasibility_records = []
    feasibility_status = "skipped"
    candidate_path = results_dir / "search_candidate.json"
    if candidate_path.exists():
        cdata = json.loads(candidate_path.read_text())
        all_constraints = cdata.get("allConstraints", [])
        active_set = set(active_indices)
        all_feasible = True
        for j, c in enumerate(all_constraints):
            if (j + 1) in active_set:  # Mathematica uses 1-based indices
                continue
            L = c.get("L", [])
            B = float(c.get("B", 0.0))
            La = sum(float(li) * float(ai) for li, ai in zip(L, a))
            slack = La + B
            feasible = slack >= -1e-6
            if not feasible:
                all_feasible = False
            feasibility_records.append({
                "constraint_index": j + 1,
                "La_plus_B": slack,
                "feasible": feasible,
            })
        feasibility_status = "PASS" if all_feasible else "FAIL"
        if feasibility_records:
            min_slack = min(r["La_plus_B"] for r in feasibility_records)
            print(f"  Inactive constraint feasibility [{feasibility_status}]: "
                  f"{len(feasibility_records)} inactive constraints, "
                  f"min slack = {min_slack:.3e}")
    else:
        print("  Inactive constraint check skipped (search_candidate.json not found)")
        print("    Run step 2 (Mathematica search) to enable this check.")

    # ── Check 3: LP optimality via SciPy re-solve ────────────────────────────
    optimality_status = "skipped"
    optimality_obj_diff = None
    if candidate_path.exists():
        try:
            import numpy as np
            from scipy.optimize import linprog

            cdata = json.loads(candidate_path.read_text())
            all_constraints = cdata.get("allConstraints", [])
            obj_c = cdata.get("objectiveC", [])
            n = int(cdata.get("numBasis", len(a)))

            if obj_c and all_constraints:
                c_vec = np.array([float(x) for x in obj_c])
                A_ub = np.array([[float(L) for L in c.get("L", [])] for c in all_constraints])
                b_ub = np.array([-float(c.get("B", 0.0)) for c in all_constraints])
                bounds = [(-100.0, 100.0)] * n

                # linprog: min c·x s.t. A_ub·x <= b_ub
                # Our constraint is L·a >= -B → -L·a <= B
                result = linprog(c_vec, A_ub=-A_ub, b_ub=b_ub, bounds=bounds, method="highs")
                if result.success:
                    certified_obj = float(np.dot(c_vec, [float(x) for x in a]))
                    scipy_obj = float(result.fun)
                    optimality_obj_diff = abs(certified_obj - scipy_obj)
                    # Allow up to 1% relative difference (numerical noise)
                    tol = max(1e-4, 0.01 * abs(scipy_obj))
                    optimality_status = "PASS" if optimality_obj_diff <= tol else "FAIL"
                    print(f"  LP optimality [{optimality_status}]: "
                          f"certified obj = {certified_obj:.6f}, "
                          f"scipy obj = {scipy_obj:.6f}, "
                          f"diff = {optimality_obj_diff:.3e}")
                else:
                    optimality_status = f"solver_failed: {result.message}"
                    print(f"  LP optimality [WARN]: SciPy LP did not converge: {result.message}")
        except ImportError:
            optimality_status = "skipped_no_scipy"
            print("  LP optimality check skipped (scipy not installed)")

    validation = {
        "timestamp": datetime.datetime.utcnow().isoformat() + "Z",
        "vertex_source": str(vertex_path),
        "num_basis": data.get("numBasis", len(a)),
        "num_active_aqei_constraints": len(active_constraints),
        "check_1_active_saturation": {
            "all_constraints_tight": all_tight,
            "tolerance_threshold": 1e-6,
            "saturation_residuals": saturation_records,
        },
        "check_2_inactive_feasibility": {
            "status": feasibility_status,
            "num_inactive_checked": len(feasibility_records),
            "records": feasibility_records,
        },
        "check_3_lp_optimality": {
            "status": optimality_status,
            "objective_diff": optimality_obj_diff,
        },
    }

    out_path = results_dir / "pipeline_validation.json"
    out_path.write_text(json.dumps(validation, indent=2))

    status = "PASS" if all_tight else "FAIL"
    print(f"Pipeline validation [{status}]: {len(active_constraints)} active constraints, "
          f"max residual = {max(r['abs_residual'] for r in saturation_records):.3e}")
    print(f"  Exported audit record to {out_path}")


def analyze_results(results_dir: Path = None) -> None:
    """Analyze and report on JSON results from Mathematica search."""
    if results_dir is None:
        results_dir = Path(__file__).parent.parent / "mathematica" / "results"

    results_dir = Path(results_dir)

    # Report on available result files.
    for fname in ["summary.json", "near_misses.json", "top_near_misses.json", "vertex.json"]:
        fpath = results_dir / fname
        if fpath.exists():
            print(f"  Found: {fname}")

    # Export pipeline validation artifact.
    export_pipeline_validation(results_dir)


if __name__ == "__main__":
    analyze_results()
